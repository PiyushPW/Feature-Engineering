{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Feature Engineering\n",
        "\n",
        "1. What is a parameter?\n",
        "  - Parameters are settings or inputs that influence how a system behaves.\n",
        "\n",
        "2. What is correlation?\n",
        "  - Correlation often refers to the relationship between two or more variables that affect a system’s performance, behavior, or output.\n",
        "\n",
        "3. Define Machine Learning. What are the main components in Machine Learning?\n",
        "  - Machine Learning (ML) is a branch of artificial intelligence that enables systems to learn from data, identify patterns, and make decisions with minimal human intervention. Instead of being explicitly programmed, ML algorithms improve their performance over time by analyzing data.\n",
        "  - Component of Machine learning:-\n",
        "  - 1. Data\n",
        "  - 2. Model\n",
        "  - 3. Algorithm\n",
        "  - 4. Evaluation\n",
        "\n",
        "4. How does loss value help in determining whether the model is good or not?\n",
        "  - 1. Training Feedback\n",
        "  - During training, the model adjusts its internal parameters to minimize the loss.\n",
        "  - A decreasing loss over time means the model is learning.\n",
        "\n",
        "  - 2. Model Comparison\n",
        "  - You can compare different models or configurations by looking at their loss values.\n",
        "  - Lower loss typically indicates better performance—though it’s not the only metric to consider.\n",
        "\n",
        "  - 3. Overfitting Detection\n",
        "  - If training loss is low but validation loss is high, the model may be overfitting (memorizing training data but failing to generalize).\n",
        "   \n",
        "\n",
        "5. What are continuous and categorical variables?\n",
        "  - Continuous Variable :- Continuous variables are numeric variables that can take any value within a range. They are measurable and often represent quantities.\n",
        "  - Categorical Variables :- Categorical variables represent distinct groups or categories. They describe qualities or labels rather than quantities.\n",
        "\n",
        "6. How do we handle categorical variables in Machine Learning? What are the common techniques?\n",
        "  - Handling categorical variables properly is essential in machine learning because most algorithms require numerical input. Since categorical data represents labels or categories, we need to convert it into a format that models can understand.\n",
        "  - Common Techniques to Handle Categorical Variables:-\n",
        "  - 1. Label Encoding\n",
        "  - 2. One-Hot Encoding\n",
        "  - 3. Ordinal Encoding\n",
        "\n",
        "7. What do you mean by training and testing a dataset?\n",
        "  - Training and testing a dataset are fundamental steps in building and evaluating a machine learning model. They help ensure that the model learns effectively and performs well on new, unseen data.\n",
        "\n",
        "8. What is sklearn.preprocessing?\n",
        "  - sklearn.preprocessing is a module in Scikit-learn, one of the most popular machine learning libraries in Python. This module provides a wide range of tools to prepare and transform data before feeding it into a machine learning model.\n",
        "\n",
        "9. What is a Test set?\n",
        "  - A test set is a crucial part of the machine learning workflow and statistical modeling process. Here's a quick breakdown tailored to your data-savvy mindset\n",
        "\n",
        "10. How do we split data for model fitting (training and testing) in Python?\n",
        "  - Using train_test_split from scikit-learn\n",
        "\n",
        "11. Why do we have to perform EDA before fitting a model to the data?\n",
        "  - Exploratory Data Analysis (EDA) is like having a conversation with your data before making big decisions based on it.\n",
        "\n",
        "14. How can you find correlation between variables in Python?\n",
        "  - Step 1: Import the Essentials\n",
        "  - Step 2: Load Your Data\n",
        "  - Step 3: Compute the Correlation Matrix\n",
        "  - Step 4: Visualize It with a Heatmap\n",
        "\n",
        "15. What is causation? Explain difference between correlation and causation with an example1?\n",
        "  - Causation means one variable directly affects another. It’s the classic cause-and-effect relationship\n",
        "  \n",
        "16. What is an Optimizer? What are different types of optimizers? Explain each with an example.\n",
        "  - An optimizer is an algorithm or method used to adjust the parameters of a model (like weights in neural networks) to minimize loss and improve accuracy.\n",
        "  - Types:-\n",
        "  - 1. SGD (Stochastic Gradient Descent)\n",
        "  - 2. SGD with Momentum\n",
        "  - 3. Adagrad\n",
        "\n",
        "17. What is sklearn.linear_model ?\n",
        "  - sklearn.linear_model is a submodule of the powerful scikit-learn library in Python that provides tools for fitting linear models.\n",
        "\n",
        "18. What does model.fit() do? What arguments must be given?\n",
        "  - The model.fit() method is your entry point to training a model. It takes in the data and learns the underlying patterns by adjusting internal parameters (like weights in regression or trees in decision trees) to minimize errors based on a loss function.\n",
        "\n",
        "19. What does model.predict() do? What arguments must be given?\n",
        "  - model.predict() is your crystal ball—it uses the learned patterns to make predictions on new or unseen data.\n",
        "\n",
        "21. What is feature scaling? How does it help in Machine Learning?\n",
        "  - Feature scaling is a preprocessing technique used to standardize or normalize the range of independent variables (features). Since many models are sensitive to the magnitude of feature values, scaling ensures that no feature dominates purely due to its scale."
      ],
      "metadata": {
        "id": "mQbTdUPdOsH3"
      }
    }
  ]
}